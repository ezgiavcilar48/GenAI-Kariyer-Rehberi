import os
import streamlit as st
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationalRetrievalChain


# Sabitler
CHROMA_PATH = "chroma_db"
PROJECT_NAME = "Kariyer AsistanÄ± Chatbotu"

# !!! API ANAHTARINIZI BURAYA YAZIN !!! 
GEMINI_API_KEY_LOCAL = "AIzaSyB_ZHXZq4FX-PRHeH6A_oFoUC2w-SC4qYY" 

# Streamlit arayÃ¼zÃ¼nÃ¼n baÅŸlÄ±klarÄ±nÄ± ayarlar
st.set_page_config(page_title=PROJECT_NAME, page_icon="ğŸ’¼")
st.title(f"ğŸ’¼ {PROJECT_NAME}")

# Oturum durumunu (Session State) kullanarak sohbet geÃ§miÅŸini baÅŸlatÄ±r
if "chat_history" not in st.session_state:
    st.session_state["chat_history"] = []

# --- Fonksiyonlar ---

def initialize_rag_chain():
    """RAG zincirini ve bileÅŸenlerini (LLM, DB, Memory) yÃ¼kler ve oluÅŸturur."""
        
    try:
        # 1. Embedding Modelini YÃ¼kle (Anahtar doÄŸrudan veriliyor)
        embeddings = GoogleGenerativeAIEmbeddings(
            model="text-embedding-004",
            google_api_key=GEMINI_API_KEY_LOCAL
        )
        
        # 2. ChromaDB VeritabanÄ±nÄ± YÃ¼kle
        vector_store = Chroma(
            persist_directory=CHROMA_PATH,
            embedding_function=embeddings
        )
        
        # 3. LLM (Generation Model) YÃ¼kle (Anahtar doÄŸrudan veriliyor)
        llm = ChatGoogleGenerativeAI(
            model="gemini-1.5-flash", 
            temperature=0.2,
            google_api_key=GEMINI_API_KEY_LOCAL
        )
        
        # 4. Sohbet HafÄ±zasÄ±nÄ± (Memory) OluÅŸtur
        memory = ConversationBufferMemory(
            memory_key="chat_history", 
            return_messages=True, 
            output_key='answer'
        )

        # 5. RAG Zincirini OluÅŸtur
        rag_chain = ConversationalRetrievalChain.from_llm(
            llm=llm,
            retriever=vector_store.as_retriever(), 
            memory=memory,
            return_source_documents=False,
            verbose=False
        )
        return rag_chain
    
    except Exception as e:
        # Hata durumunda (Ã¶rneÄŸin DB oluÅŸturulmamÄ±ÅŸsa)
        st.error(f"Uygulama baÅŸlatÄ±lamadÄ±. VeritabanÄ±nÄ±n ({CHROMA_PATH}) oluÅŸturulduÄŸundan emin olun. Hata: {e}")
        return None

# RAG zincirini Streamlit'in Ã¶nbelleÄŸine alÄ±r
rag_chain = st.cache_resource(initialize_rag_chain)()

# --- ArayÃ¼z ve KullanÄ±cÄ± EtkileÅŸimi ---

# Sohbet geÃ§miÅŸini arayÃ¼zde gÃ¶sterir
for message in st.session_state["chat_history"]:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# KullanÄ±cÄ±dan gelen giriÅŸi alÄ±r ve iÅŸler
if user_query := st.chat_input("Kariyer yolculuÄŸun hakkÄ±nda bir soru sor..."):
    
    # KullanÄ±cÄ± mesajÄ±nÄ± geÃ§miÅŸe ekler ve arayÃ¼zde gÃ¶sterir
    st.session_state["chat_history"].append({"role": "user", "content": user_query})
    with st.chat_message("user"):
        st.markdown(user_query)

    # RAG zinciri mevcutsa devam eder
    if rag_chain:
        with st.spinner("Kariyer asistanÄ± yanÄ±t hazÄ±rlÄ±yor..."):
            try:
                # RAG zincirini Ã§alÄ±ÅŸtÄ±rÄ±r
                response = rag_chain.invoke({"question": user_query})
                
                # Modelden gelen yanÄ±tÄ± alÄ±r
                assistant_response = response["answer"]
                
                # Asistan yanÄ±tÄ±nÄ± geÃ§miÅŸe ekler ve arayÃ¼zde gÃ¶sterir
                st.session_state["chat_history"].append({"role": "assistant", "content": assistant_response})
                with st.chat_message("assistant"):
                    st.markdown(assistant_response)

            except Exception as e:
                # LLM veya API hatasÄ± yakalanÄ±rsa
                error_msg = f"YanÄ±t oluÅŸturulurken bir sorun oluÅŸtu. Hata: {e}"
                st.session_state["chat_history"].append({"role": "assistant", "content": error_msg})
                with st.chat_message("assistant"):
                    st.error(error_msg)
    else:
        # RAG zinciri baÅŸlatÄ±lamadÄ±ysa uyarÄ± gÃ¶sterir
        with st.chat_message("assistant"):
            st.warning("Chatbot sistemi hazÄ±r deÄŸil. LÃ¼tfen kurulum adÄ±mlarÄ±nÄ± kontrol edin.")